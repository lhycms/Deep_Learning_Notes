{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "medieval-pharmaceutical",
   "metadata": {},
   "source": [
    "# 04 BackPropagation: 求梯度dLoss  / dWeights(随后用于优化算法)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-check",
   "metadata": {},
   "source": [
    "## 链式法则 in Computation Graph\n",
    "\n",
    "<img src=\"./picut/cg_2.png\" height=\"400\" width=\"400\">\n",
    "\n",
    "## BackPropagation流程\n",
    "1. `Forward pass`: Compute loss (绿)\n",
    "2. Compute local gradients（蓝）\n",
    "3. `Backward pass`: Compute dLoss / dWeights using the Chain Rules （红）\n",
    "4. Update weights\n",
    "5. Next forward pass and backward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-copying",
   "metadata": {},
   "source": [
    "# 1. PyTorch实现简单的Forward pass和Backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "legal-weapon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "certain-anthony",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(1.)\n",
    "y = torch.tensor(2.)\n",
    "w = torch.tensor(1., requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "unlimited-direction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# forward pass\n",
    "# 因为 w.requires_grad=True, 所以一旦利用w开始计算，PyTorch就会自动建立computation graph\n",
    "y_hat = w * x\n",
    "loss = (y_hat - y) ** 2\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-trailer",
   "metadata": {},
   "source": [
    "## Why can't call `.backward()` method again?\n",
    "To reduce memory usage, during the .backward() call, all the intermediary results(such as loss, y_hat and so on) are deleted in computation graph when they are not needed anymore. Hence if you try to call .backward() again, the intermediary results don’t exist and the backward pass cannot be performed (and you get the error you see).\n",
    "You can call .backward(retain_graph=True) to make a backward pass that will not delete intermediary results, and so you will be able to call .backward() again. All but the last call to backward should have the retain_graph=True option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "responsible-sullivan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# backward pass\n",
    "w.grad.zero_()\n",
    "loss.backward()\n",
    "w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-verification",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.9",
   "language": "python",
   "name": "python3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
