{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "great-sheffield",
   "metadata": {},
   "source": [
    "# 05 Gradient Descent with Autograd and Backpropagation\n",
    "\n",
    "\n",
    "1. Prediction: PyTorch Model\n",
    "2. Gradient Computation: Autograd\n",
    "3. Loss Computation: PyTorch Loss\n",
    "4. Parameters Updates: PyTorch Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prime-terrain",
   "metadata": {},
   "source": [
    "# Main Steps in Neural Networks\n",
    "1. Prediction: Manually\n",
    "2. Gradient Computation:  <font color=#A52A2A size=3>Autograd</font>\n",
    "3. Loss Computation: Manually\n",
    "4. Parameters Updates: Manually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-correspondence",
   "metadata": {},
   "source": [
    "# 1. 手动实现Gradient Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "medical-satisfaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "opening-equipment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = w * x\n",
    "# f = 2 * x\n",
    "X = np.array([1, 2, 3, 4], dtype=np.float32)\n",
    "Y = np.array([2, 4, 6, 8], dtype=np.float32)\n",
    "\n",
    "w = 0.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "prostate-punch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Prediction\n",
    "def forward(x):\n",
    "    return w * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "british-russia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = MSE\n",
    "def loss(y, y_predicted):\n",
    "    return ((y_predicted - y)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "modified-joint",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient\n",
    "# MSE = 1/N  * (w*x - y)**2\n",
    "# dJ/dw = 1/N * 2*x * (w*x - y)\n",
    "def gradient(x, y, y_predicted):\n",
    "    return np.dot(2*x, (y_predicted-y)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "theoretical-jackson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: 0.000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Prediction before training: {forward(5):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "amended-taxation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: w=1.200, loss=30.00000000\n",
      "epoch 2: w=1.680, loss=4.79999924\n",
      "epoch 3: w=1.872, loss=0.76800019\n",
      "epoch 4: w=1.949, loss=0.12288000\n",
      "epoch 5: w=1.980, loss=0.01966083\n",
      "epoch 6: w=1.992, loss=0.00314574\n",
      "epoch 7: w=1.997, loss=0.00050331\n",
      "epoch 8: w=1.999, loss=0.00008053\n",
      "epoch 9: w=1.999, loss=0.00001288\n",
      "epoch 10: w=2.000, loss=0.00000206\n"
     ]
    }
   ],
   "source": [
    "# Training \n",
    "learning_rate = 0.01\n",
    "n_iters = 10\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # gradients\n",
    "    dw = gradient(X, Y, y_pred)\n",
    "    \n",
    "    #update weights\n",
    "    w -= learning_rate * dw\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        print(f'epoch {epoch+1}: w={w:.3f}, loss={l:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "reasonable-timothy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction after training: 9.999\n"
     ]
    }
   ],
   "source": [
    "print(f\"Prediction after training: {forward(5):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-commitment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-illustration",
   "metadata": {},
   "source": [
    "# 2. Gradient Computation with Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bright-generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "comic-proof",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([1., 2., 3. ,4.], dtype=torch.float32)\n",
    "Y = torch.tensor([2., 4., 6., 8.], dtype=torch.float32)\n",
    "w = torch.tensor([0.0], dtype=torch.float32, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "defined-second",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "def forward(x):\n",
    "    return w * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "saving-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss = MSE\n",
    "def loss(y, y_predicted):\n",
    "    return ((y_predicted - y)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fancy-tours",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient\n",
    "# MSE = (w*x - y)**2\n",
    "# dJ/dw = 2*x * (w*x - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "armed-twenty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: 0.0\n"
     ]
    }
   ],
   "source": [
    "print('Prediction before training: {0}'.format(float(forward(5))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "extended-holocaust",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10: w=0.29999998211860657, loss=30.0\n",
      "epoch 10: w=0.5549999475479126, loss=21.674999237060547\n",
      "epoch 10: w=0.7717499136924744, loss=15.660187721252441\n",
      "epoch 10: w=0.9559874534606934, loss=11.314486503601074\n",
      "epoch 10: w=1.1125893592834473, loss=8.17471694946289\n",
      "epoch 10: w=1.2457009553909302, loss=5.9062323570251465\n",
      "epoch 10: w=1.358845829963684, loss=4.2672529220581055\n",
      "epoch 10: w=1.4550189971923828, loss=3.083089828491211\n",
      "epoch 10: w=1.5367661714553833, loss=2.227532148361206\n",
      "epoch 10: w=1.6062512397766113, loss=1.609391689300537\n",
      "epoch 10: w=1.6653136014938354, loss=1.1627856492996216\n",
      "epoch 10: w=1.7155165672302246, loss=0.8401124477386475\n",
      "epoch 10: w=1.758189082145691, loss=0.6069811582565308\n",
      "epoch 10: w=1.7944607734680176, loss=0.4385439455509186\n",
      "epoch 10: w=1.825291633605957, loss=0.3168478012084961\n",
      "epoch 10: w=1.8514978885650635, loss=0.22892260551452637\n",
      "epoch 10: w=1.873773217201233, loss=0.1653965264558792\n",
      "epoch 10: w=1.8927072286605835, loss=0.11949898302555084\n",
      "epoch 10: w=1.9088011980056763, loss=0.08633805811405182\n",
      "epoch 10: w=1.9224810600280762, loss=0.0623791441321373\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_iters = 20\n",
    "for i in range(n_iters):\n",
    "    # Prediction\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "    # Loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # Gradient\n",
    "    l.backward()\n",
    "    \n",
    "    # Update weights\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate * w.grad\n",
    "    \n",
    "    # Zero w.grad\n",
    "    w.grad.zero_()\n",
    "    \n",
    "    print('epoch {0}: w={1}, loss={2}'.format(epoch+1, float(w), l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "featured-reproduction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction after training: 9.612405776977539\n"
     ]
    }
   ],
   "source": [
    "print('Prediction after training: {0}'.format(float(forward(5))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-heaven",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.9",
   "language": "python",
   "name": "python3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
