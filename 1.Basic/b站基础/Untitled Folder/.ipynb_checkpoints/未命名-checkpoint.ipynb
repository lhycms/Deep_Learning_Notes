{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "breathing-riding",
   "metadata": {},
   "source": [
    "- `Leaf Variables`: Tensors you create directly. \n",
    "- Tensors that are the result of a differentiable operation are `not leaf variables`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-figure",
   "metadata": {},
   "source": [
    "# RuntimeError: a leaf Variable that requires grad is being used in an in-place operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-radical",
   "metadata": {},
   "source": [
    "# 1. 区分是否是叶子节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "worldwide-sheet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "supposed-thailand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example\n",
    "\n",
    "# leaf variable\n",
    "w = torch.tensor([1.0, 2.0, 3.0])\n",
    "\n",
    "# also leaf variable\n",
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True) \n",
    "\n",
    "# not a leaf variable\n",
    "y = x + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "satisfactory-traveler",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True False\n"
     ]
    }
   ],
   "source": [
    "print(w.is_leaf, x.is_leaf, y.is_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-research",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "signal-hartford",
   "metadata": {},
   "source": [
    "# 2. Inplace Operation\n",
    "\n",
    "An in-place operation is something which modifies the data of a variable. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "collectible-charter",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a leaf Variable that requires grad is being used in an in-place operation.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c5630e1317f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# in-place\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;31m# not in place\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: a leaf Variable that requires grad is being used in an in-place operation."
     ]
    }
   ],
   "source": [
    "x += 1  # in-place\n",
    "y = x + 1 # not in place"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "allied-enemy",
   "metadata": {},
   "source": [
    "# 3. 解决上述报错"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-president",
   "metadata": {},
   "source": [
    "## 3.1 法一\n",
    " If you want the operation to be differentiable, you can work around the limitation by cloning the leaf variable (or use a non-inplace version of the operator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "simple-theology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 3., 4.], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x2 = x.clone()  # clone the variable\n",
    "x2 += 1  # in-place operation\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiac-court",
   "metadata": {},
   "source": [
    "## 3.2 法二\n",
    "If you don’t intend for the operation to be differentiable, you can use torch.no_grad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "russian-climate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.6409, 2.9962, 2.0906], requires_grad=True)\n",
      "True\n",
      "tensor([2.6409, 2.9962, 2.0906], requires_grad=True)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x += 1\n",
    "    print(x)\n",
    "    print(x.requires_grad)\n",
    "print(x)\n",
    "print(x.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-plymouth",
   "metadata": {},
   "source": [
    "# 4. `with no_grad():` 上下文管理器\n",
    "\n",
    "The wrapper `torch.no_grad()` and `tensor.requires_grad`都是用来控制是否计算梯度的，但是wrapper `torch.no_grad()` 优先级高一些"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.9",
   "language": "python",
   "name": "python3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
