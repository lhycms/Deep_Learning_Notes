<!--
 * @Descripttion: 
 * @version: 
 * @Author: sch
 * @Date: 2022-03-07 14:54:47
 * @LastEditors: sch
 * @LastEditTime: 2022-03-07 16:38:37
-->
<font color="orange" size="4">

Why Normalize Inputs?
---------------------
- If `feature_1` range from -200 to 200, `feature_2` range from -10 to 10. Once we normalized the data. To accommodate this range difference between the features some weights would have to be large and then some to be small.
- Improve training speed.

</font>

# 1. Batch Normalization
<font color="red" size="4">


- We have normalized the inputs but what about hidden representatives?

</font>

<font color="orange" size="4">

- In order to bring all the activation values to the same scale, we `normalize the activation values` such that the hidden representation doesn't vary drastically and also helps us to get improvement in the training speed.

</font>

## 1.1. Why is it called `batch normalization`?
<font color="orange" size="4">

- Since we are `computing the mean and standard deviation from a single batch`, as opposed to computing it from the entire data. Batch Normalization is done individually at each hidden neuron in the network.

</font>

## 1.2. Learning Gamma and Beta
<font color="orange" size="4">


- Since we are normalizing all the activations in the network, are we enforcing some constraints that could deteriorate the performance of the network?

- In order to maintain the representaive power of the hidden neural network, batch normalization introduces two extra parameters -- `Gamma` and `Beta`. 

- Once we normalize the activation, we need to perform one more step to get the final activation value that can be feed as the input to anthor layer.
    1. Gamma  == mean
    2. Beta == standard deviation
$$ h_{ij}^{norm} = ( h_{ij} - u_j ) / \sigma_j $$

$$ h_{ij}^{final} = \gamma_j * h_{ij}^{norm} + \beta_j $$

</font>


# 2. Demo
```python
import torchvision
import torchvision.transforms as transforms

import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader


# hyper parameters
batch_size = 512

# 0) Data preparation
train_dataset = torchvision.datasets.MNIST(root="./data", train=True,
                                    download=True,
                                    transform=transforms.ToTensor())
test_dataset = torchvision.datasets.MNIST(root="./data", train=False,
                                    download=False,
                                    transform=transforms.ToTensor())

train_loader = DataLoader(dataset=train_dataset,
                        batch_size=batch_size,
                        shuffle=True)
test_loader = DataLoader(dataset=test_dataset,
                        batch_size=batch_size,
                        shuffle=False)

# 1) model
class MyNet(nn.Module):
    def __init__(self):
        super(MyNet, self).__init__()
        self.classifier = nn.Sequential(
            nn.Linear(784, 48),
            nn.ReLU(),
            nn.Linear(48, 24),
            nn.ReLU(),
            nn.Linear(24, 10)
        )

    def forward(self, x):
        x = x.view(x.size(0), -1)
        # 将 tensor 拉伸为一行
        x = self.classifier(x)
        return x

class MyNetBN(nn.Module):
    def __init__(self):
        super(MyNetBN, self).__init__()
        self.classifier = nn.Sequential(
            nn.Linear(784, 48),
            nn.BatchNorm1d(48),
            nn.ReLU(),
            nn.Linear(48, 24),
            nn.BatchNorm1d(24),
            nn.ReLU(),
            nn.Linear(24, 10)
        )
    
    def forward(self, x):
        x = x.view(x.size(0), -1)
        x = self.classifier(x)
        return x


model = MyNet()
model_bn = MyNetBN()

# 2) loss function and optimizer
loss_fn = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.01)
optimizer_bn = optim.SGD(model_bn.parameters(), lr=0.01)


# 3) training loop
#   ...
```