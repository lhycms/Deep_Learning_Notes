<!--
 * @Descripttion: 
 * @version: 
 * @Author: sch
 * @Date: 2022-03-01 22:10:08
 * @LastEditors: sch
 * @LastEditTime: 2022-03-02 10:30:51
-->
# Dataset and DataLoader - Batch Training
<font color="red" size="4">

Note
----
1. 如果我们在整个训练集上进行梯度下降(`Gradient Descent`)，这会非常消耗时间。
2. 所以对于大型训练集，我们应该把训练集分为更小的`batches`。我们的训练过程看起来如下：
```python
# Training loop
for epoch in range(1, epochs_num + 1):
    # loop over all batches 
    for i in range(total_batches):
        x_batch, y_batch = ...
```

</font>

# 1. 关于 `batch training` 的关键术语
<font color="orange" size="4">

Terms
-----
1. `epoch`: `1 forward pass` and `1 backward pass` of ALL training samples

2. `batch_size`: number of training samples in one `forward & backward` pass

3. `number of iterations`: number of passes, each pass using [batch_size] number of samples

e.g. 100 samples, batch_size=20 --> 100/20 = 5 iterations for 1 epoch

</font>


# 1. `Dataset` derived class 的编写
```python
'''
Descripttion: 
version: 
Author: sch
Date: 2022-02-25 16:53:30
LastEditors: sch
LastEditTime: 2022-03-01 22:39:37
'''
import torch 
import torchvision
from torch.utils.data import Dataset, DataLoader
import numpy as np
import math


class WineDataset(Dataset):
    ### The first row is header, we want to predict the categories of wine( 3 kinds )
    ### 第一列是target, 剩下的列是features
    def __init__(self):
        # data loading
        xy = np.loadtxt("/Users/mac/Desktop/pytorchTutorial-master/data/wine/wine.csv",
                        delimiter=',', dtype=np.float32, skiprows=1)
        self.x = torch.from_numpy(xy[:, 1:])
        self.y = torch.from_numpy(xy[:, [0]]) # we put 0 in another [], so the size of it = (n_samples, 1)
        self.n_samples, self.n_features = self.x.shape


    def __getitem__(self, index):
        # dataset[0]
        return self.x[index], self.y[index]


    def __len__(self):
        # len(dataset)
        return self.n_samples


dataset = WineDataset()
first_data = dataset[0]
features, labels = first_data
print(features, labels)
```

Output:
```shell
tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,
        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,
        1.0650e+03]) tensor([1.])
```


# 2. `Dataset` derived class 的编写注意事项
## 2.1. `torch.utils.data.Dataset`: Dataset 的类型

## 2.2. `np.loadtxt(csv_path, delimiter, dtype, skiprows)`:读取`csv`数据
```python
from torch.utils.data import Dataset

class WineDataset(Dataset):

    def __init__(self):
        xy = np.loadtxt(csv_path, delimiter=',', dtype=np.float32, skiprows=1)
        self.x = xy[:, 1:]
        self.y = xy[:, [0]]
        self.n_samples, self.n_features = xy.shape

    def __getitem__(self, index):
        return self.x[index], self.y[index]
    
    def __len__(self):
        return self.n_samples
```


# 3. `torch.utils.data.DataLoader(dataset=dataset, batch_size, shuffle, num_workers)`
<font color="red" size="4" >

Note
----
1. `num_workers`：进程数，一般设置为`0`（否则会报各种长篇大论的错）

</font>

## 3.1. `DataLoader()` 可以做迭代器
```python
...
data = WineDataset()
dataloader = DataLoader(dataset=dataset,
                        batch_size=4,
                        shuffle=True,
                        num_workers=2)

dataiter = iter(dataloader)
data = dataiter.next()
features, labels = data
print(features, labels)
```
Output:
```shell
tensor([[1.3510e+01, 1.8000e+00, 2.6500e+00, 1.9000e+01, 1.1000e+02, 2.3500e+00,
         2.5300e+00, 2.9000e-01, 1.5400e+00, 4.2000e+00, 1.1000e+00, 2.8700e+00,
         1.0950e+03],
        [1.4220e+01, 3.9900e+00, 2.5100e+00, 1.3200e+01, 1.2800e+02, 3.0000e+00,
         3.0400e+00, 2.0000e-01, 2.0800e+00, 5.1000e+00, 8.9000e-01, 3.5300e+00,
         7.6000e+02],
        [1.2370e+01, 9.4000e-01, 1.3600e+00, 1.0600e+01, 8.8000e+01, 1.9800e+00,
         5.7000e-01, 2.8000e-01, 4.2000e-01, 1.9500e+00, 1.0500e+00, 1.8200e+00,
         5.2000e+02],
        [1.3110e+01, 1.9000e+00, 2.7500e+00, 2.5500e+01, 1.1600e+02, 2.2000e+00,
         1.2800e+00, 2.6000e-01, 1.5600e+00, 7.1000e+00, 6.1000e-01, 1.3300e+00,
         4.2500e+02]]) tensor([[1.],
        [1.],
        [2.],
        [3.]])
```

## 3.2. Demo
```python
import torch
import numpy as np
from torch.utils.data import Dataset, DataLoader


# 1. Custom path
dataset_path = "/data/home/liuhanyu/Interaction/torch_test/data/wine.csv"


# 2. Class code
class WineDataset(Dataset):
    '''
    Attribute
    ---------
        1. self.x: torch.tensor
            
        2. self.y: torch.tensor

        3. self.n_samples: int
            数据集的尺寸
        4. self.n_features: int
            数据特征的数目
    '''
    def __init__(self, dataset_path:str):
        xy = np.loadtxt(dataset_path,
                        delimiter=",",
                        dtype=np.float32,
                        skiprows=1,
                        )
        
        self.x = torch.from_numpy( xy[:, 1:] )
        self.y = torch.from_numpy( xy[:, [0]] )
        
        self.n_samples, self.n_features = self.x.shape
        
    
    def __getitem__(self, index):
        return self.x[index], self.y[index]
    
    
    def __len__(self):
        return self.n_samples


if __name__ == "__main__":
    data = WineDataset(dataset_path=dataset_path)
    dataloader = DataLoader(dataset=data,
                            batch_size=3,
                            shuffle=True)
    dataiter = iter(dataloader)
    f, l = dataiter.next()
    print(f, l)
```
Output:
```shell
tensor([[1.2210e+01, 1.1900e+00, 1.7500e+00, 1.6800e+01, 1.5100e+02, 1.8500e+00,
         1.2800e+00, 1.4000e-01, 2.5000e+00, 2.8500e+00, 1.2800e+00, 3.0700e+00,
         7.1800e+02],
        [1.4100e+01, 2.1600e+00, 2.3000e+00, 1.8000e+01, 1.0500e+02, 2.9500e+00,
         3.3200e+00, 2.2000e-01, 2.3800e+00, 5.7500e+00, 1.2500e+00, 3.1700e+00,
         1.5100e+03],
        [1.3510e+01, 1.8000e+00, 2.6500e+00, 1.9000e+01, 1.1000e+02, 2.3500e+00,
         2.5300e+00, 2.9000e-01, 1.5400e+00, 4.2000e+00, 1.1000e+00, 2.8700e+00,
         1.0950e+03]]) tensor([[2.],
        [1.],
        [1.]])
```

# 4. `torch.utils.data.DataLoader(dataset, batch_size, shuffle, num_workers)`: Batches 训练盛景网络的 `training loop` 写法
<font color="red" size="4">

Note
----
1. `math.ceil()`: 返回数字的上入指数

</font>

```python
import torch 
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import numpy as np
import math


class WineDataset(Dataset):

    def __init__(self):
        xy = np.loadtxt("/Users/mac/Desktop/pytorchTutorial-master/data/wine/wine.csv",
                        delimiter=',',
                        dtype=np.float32,
                        skiprows=1)
        self.x = torch.from_numpy(xy[:, 1:])
        self.y = torch.from_numpy(xy[:, [0]])
        self.n_samples, self.features = self.x.size()
    
    def __getitem__(self, index):
        return self.x[index], self.y[index]

    def __len__(self):
        return self.n_samples


# Data loading
dataset = WineDataset()
dataloader = DataLoader(dataset=dataset,
                        batch_size=4,
                        shuffle=True,
                        num_workers=0)


# Training loop
num_epochs = 2
n_samples = len(dataset)
# math.ceil(): 返回数字的上入指数
n_iterations = math.ceil(len(dataset) / 4)

 
for epoch in range(1, num_epochs + 1):
    for i, (inputs, outputs) in enumerate(dataloader):
        '''
        省略以下训练过程：
            1. forward
            2. backward
            3. gradient
            4. update
            5. zero gradients
        '''
        # Output information
        if (i+1) % 5 == 0:
            print("Epoch {0}/{1}, step {2}/{3}, inputs {4}".format(epoch,
                                                                num_epochs,
                                                                i+1,
                                                                n_iterations,
                                                                inputs.size()))
``` 



# 5. `Error`: 神经网络模型输出为`nan/inf`，或损失值为`nan/inf`
<font color="red" size="4"><b>

Debug 方法：(在将input输入神经网络前，做以下两步)
----------
1. Normalize the inputs. ( 将输入正则化 )
2. Lower the learning rate. ( 降低学习率 )

</b></font>