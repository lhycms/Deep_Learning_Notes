{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Website:  https://www.geeksforgeeks.org/implementing-an-autoencoder-in-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /Users/mac/我的文件/Notebook/Quantum_Mechanics/algorithm_implementation/7.Encoder&Decoder/code/data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 7101440/9912422 [13:21<36:55, 1268.57it/s]  "
     ]
    }
   ],
   "source": [
    "# Transforms images to a PyTorch Tensor\n",
    "tensor_transform = transforms.ToTensor()\n",
    "\n",
    "# Download the MNIST Dataset\n",
    "dataset = datasets.MNIST(\n",
    "                root=\"/Users/mac/我的文件/Notebook/Quantum_Mechanics/algorithm_implementation/7.Encoder&Decoder/code/data\",\n",
    "                train=True,\n",
    "                download=True,\n",
    "                transform=tensor_transform,\n",
    "                )\n",
    "\n",
    "# DataLoader is used to load the dataset for training\n",
    "loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                    batch_size=32,\n",
    "                                    shuffle=True,\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create Autoencoder Class\n",
    "In this coding snippet, the encoder section reduces the dimensionality of the data sequentially as given by:\n",
    "```shell\n",
    "28*28 = 784 ==> 128 ==> 64 ==> 36 ==> 18 ==> 9\n",
    "```\n",
    "Where the number of input nodes is 784 that are coded into 9 nodes in the latent space. Whereas, in the decoder section, the dimensionality of the data is linearly increased to the original input size, in order to reconstruct the input.\n",
    "```shell\n",
    "9 ==> 18 ==> 36 ==> 64 ==> 128 ==> 784 ==> 28*28 = 784\n",
    "```\n",
    "Where the input is the 9-node latent space representation and the output is the 28*28 reconstructed input.\n",
    "\n",
    "The encoder starts with 28*28 nodes in a Linear layer followed by a ReLU layer, and it goes on until the dimensionality is reduced to 9 nodes. The decryptor uses these 9 data representations to bring back the original image by using the inverse of the encoder architecture. The decryptor architecture uses a Sigmoid Layer to range the values between 0 and 1 only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a PyTorch class\n",
    "class AE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(28 * 28, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 36),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(36, 18),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(18, 9)\n",
    "        )\n",
    "    \n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(9, 18),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(18, 36),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(36, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 28 * 28),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(x)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Initializing Model\n",
    "We validate the model using the `Mean Squared Error function`, and we use an Adam Optimizer with a `learning rate` $0.1$ and `weight decay of` $10^{-8}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Initialization\n",
    "model = AE()\n",
    "\n",
    "# Validation using MSE Loss function\n",
    "loss_function = torch.nn.MSELoss()\n",
    "\n",
    "# Using an Adam Optimizer with lr=0.1\n",
    "optimizer = torch.optim.Adam(\n",
    "                        model.parameters(),\n",
    "                        lr=1e-1,\n",
    "                        weight_decay=1e-8,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create Output Generation\n",
    "1. The output against each epoch is computed by passing as a parameter into the Model() class and the final tensor is stored in an output list. The image into (-1, 784) and is passed as a parameter to the Autoencoder class, which in turn returns a reconstructed image. The loss function is calculated using MSELoss function and plotted. In the optimizer, the initial gradient values are made to zero using zero_grad(). loss.backward() computes the grad values and stored. Using the step() function, the optimizer is updated.\n",
    "2. The original image and the reconstructed image from the outputs list are detached and transformed into a NumPy Array for plotting the images.\n",
    "\n",
    "Note\n",
    "----\n",
    "This snippet takes 15 to 20 mins to execute, depending on the processor type. Initialize epoch = 1, for quick results. Use a GPU/TPU runtime for faster computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "outputs = []\n",
    "losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for (image, _) in loader:\n",
    "\n",
    "        # Reshaping the image to (-1, 784)\n",
    "        image = image.reshape(-1, 28*28)\n",
    "\n",
    "        # Output of AutoEncoder\n",
    "        reconstructed = model(image)\n",
    "\n",
    "        # Calculating the loss function\n",
    "        loss = loss_function(reconstructed, image)\n",
    "\n",
    "        # The gradient are set to zero,\n",
    "        # the gradient is computed and stored\n",
    "        # .step() performs parameters update\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Storing the losses in a list for plotting \n",
    "        losses.append(loss)\n",
    "    outputs.append((epoch, image, reconstructed))\n",
    "\n",
    "# Defining the Plot Style\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    " \n",
    "# Plotting the last 100 values\n",
    "plt.plot(losses[-100:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. `Input/Reconstructed` Input to/from Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, item in enumerate(image):\n",
    "\n",
    "    # Reshape the array for plotting\n",
    "    item = item.reshape(-1, 28, 28)\n",
    "    plt.imshow(item[0])\n",
    "\n",
    "for i, item in enumerate(reconstructed):\n",
    "  item = item.reshape(-1, 28, 28)\n",
    "  plt.imshow(item[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"steelblue\" size=\"4\">\n",
    "\n",
    "Summary\n",
    "-------\n",
    "1. Although the rebuilt pictures appear to be adequate, they are extremely grainy. \n",
    "2. To enhance this outcome, extra layers and/or neurons may be added, or the autoencoder model could be built on convolutions neural network architecture. \n",
    "3. For `dimensionality reduction`, autoencoders are quite beneficial. \n",
    "4. However, it might also be used for data denoising and understanding a dataset’s spread.\n",
    "\n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('research')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b361d90544c21c7e570702d0c4d23653c8dcac4c1ecf309667aae54eeacb0d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
