{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    # input: batch_size * seq_len * input_dim\n",
    "    # q: batch_size * input_dim * dim_k\n",
    "    # k: batch_size * input_dim * dim_k\n",
    "    # v: batch_size * input_dim * dim_v\n",
    "    def __init__(self, input_dim, dim_k, dim_v):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.q = nn.Linear(input_dim, dim_k)\n",
    "        self.k = nn.Linear(input_dim, dim_k)\n",
    "        self.v = nn.Linear(input_dim, dim_v)\n",
    "        self._norm_fact = 1 / sqrt(dim_k)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        Q = self.q(x)   # Q: batch_size * seq_len * dim_k\n",
    "        K = self.k(x)   # K: batch_size * seq_len * dim_k\n",
    "        V = self.v(x)   # V: batch_size * seq_len * dim_v\n",
    "\n",
    "        # Q * K.T: batch_size * seq_len * seq_len\n",
    "        atten = nn.Softmax(dim=-1)(torch.bmm(Q, K.permute(0, 2, 1)) * self._norm_fact)\n",
    "        \n",
    "        # Q * K.T * V: batch_size * seq_len * dim_v\n",
    "        output = torch.bmm(atten, V)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.7180,  0.1240],\n",
      "         [-0.5025, -0.3688],\n",
      "         [-1.4666, -1.7369]],\n",
      "\n",
      "        [[-0.4069,  1.3145],\n",
      "         [ 1.9539,  0.5227],\n",
      "         [-1.3205, -2.3105]],\n",
      "\n",
      "        [[ 0.7404,  1.4654],\n",
      "         [ 0.7514, -1.5712],\n",
      "         [-0.7534, -0.8105]],\n",
      "\n",
      "        [[ 0.9951, -0.8740],\n",
      "         [ 0.0501, -0.8154],\n",
      "         [ 0.1744,  0.2346]]])\n",
      "torch.Size([4, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(4, 3, 2)\n",
    "print(X)\n",
    "print(X.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.7596,  0.2057,  0.0712, -0.3409, -0.4780],\n",
      "         [-0.7930,  0.1943,  0.0763, -0.3505, -0.4690],\n",
      "         [-0.8356,  0.1842,  0.0718, -0.3530, -0.4443]],\n",
      "\n",
      "        [[ 0.2769,  0.6979, -0.4471,  0.2858, -0.3194],\n",
      "         [-0.2596,  0.3906, -0.0443, -0.1604, -0.5647],\n",
      "         [ 0.7067,  1.1031, -1.1776,  1.0127,  0.3715]],\n",
      "\n",
      "        [[ 0.2204,  0.6942, -0.4782,  0.3054, -0.2562],\n",
      "         [-0.1416,  0.6858, -0.7164,  0.4663,  0.1968],\n",
      "         [-0.0530,  0.7529, -0.8249,  0.5780,  0.2882]],\n",
      "\n",
      "        [[ 0.0608,  0.7631, -0.7695,  0.5450,  0.1694],\n",
      "         [ 0.0708,  0.7870, -0.8234,  0.5954,  0.2303],\n",
      "         [ 0.0765,  0.7644, -0.7615,  0.5402,  0.1526]]],\n",
      "       grad_fn=<BmmBackward0>)\n",
      "torch.Size([4, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "self_attention = SelfAttention(2, 4, 5)\n",
    "res = self_attention(X)\n",
    "print(res)\n",
    "print(res.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionMultiHead(nn.Module):\n",
    "    # input: batch_size * seq_len * input_dim\n",
    "    # q: batch_size * input_dim * dim_k\n",
    "    # k: batch_size * input_dim * dim_k\n",
    "    # v: batch_size * input_dim * dim_v\n",
    "    def __init__(self, input_dim, dim_k, dim_v, num_heads):\n",
    "        super(SelfAttentionMultiHead, self).__init__()\n",
    "        assert dim_k % num_heads == 0\n",
    "        assert dim_v % num_heads == 0\n",
    "        self.q = nn.Linear(input_dim, dim_k)\n",
    "        self.k = nn.Linear(input_dim, dim_k)\n",
    "        self.v = nn.Linear(input_dim, dim_v)\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.dim_k = dim_k\n",
    "        self.dim_v = dim_v\n",
    "        self._norm_fact = 1 / sqrt(dim_k)\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        Q = self.q(x).reshape(-1, x.shape[0], x.shape[1], self.dim_k // self.num_heads)\n",
    "        K = self.k(x).reshape(-1, x.shape[0], x.shape[1], self.dim_k // self.num_heads)\n",
    "        V = self.v(x).reshape(-1, x.shape[0], x.shape[1], self.dim_v // self.num_heads)\n",
    "        \n",
    "        print(x.shape)\n",
    "        print(Q.size())\n",
    "\n",
    "        atten = nn.Softmax(dim=-1)(torch.matmul(Q, K.permute(0, 1, 3, 2))) * self._norm_factor # Q * K.T() # batch_size * seq_len * seq_len\n",
    "\n",
    "        output = torch.matmul(atten, V).reshape(x.shape[0], x.shape[1], -1) # Q * K.T() * V # batch_size * seq_len * dim_v\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 5.8137e-01, -6.9116e-01, -2.1204e-01,  9.1610e-01,  7.1715e-02,\n",
      "           6.1210e-01,  8.6303e-02, -7.8856e-02, -1.7583e+00,  1.4410e-01,\n",
      "          -1.5569e+00,  1.5800e+00],\n",
      "         [ 9.8535e-01, -6.9716e-01,  4.1188e-01, -8.6874e-01, -2.5236e+00,\n",
      "          -1.0130e+00,  1.2952e+00,  5.3968e-01,  1.9581e-01, -2.9223e-01,\n",
      "           7.9378e-01, -1.3396e-01],\n",
      "         [ 2.1546e-01, -3.4884e-01,  3.5852e-01,  5.9518e-01, -2.8232e+00,\n",
      "          -1.4204e+00,  2.0986e-01, -2.1886e-01,  9.2015e-01,  1.2289e+00,\n",
      "          -2.4733e-01, -2.0131e+00],\n",
      "         [ 6.6980e-01, -4.4293e-01, -6.5551e-01, -6.3324e-01, -6.7950e-01,\n",
      "          -1.1531e+00,  2.1958e+00, -1.0471e+00, -7.9204e-01, -5.7783e-01,\n",
      "           4.1470e-01, -2.6242e-01],\n",
      "         [-1.2670e-01,  8.8041e-01,  1.6829e+00,  1.0102e+00, -7.8223e-01,\n",
      "           1.0122e+00,  1.7825e+00, -9.7064e-01,  1.4639e+00, -8.5901e-01,\n",
      "           6.4491e-01,  7.1196e-01],\n",
      "         [ 8.5569e-01, -3.0760e-01, -4.2791e-01,  9.1599e-01,  2.2121e-01,\n",
      "           9.2609e-01,  1.2777e+00, -1.3136e-02, -7.0454e-01,  7.2459e-01,\n",
      "          -6.2745e-01, -4.7661e-02],\n",
      "         [-8.4993e-01, -1.0241e+00,  7.9750e-02, -2.4219e+00,  3.8238e-01,\n",
      "          -3.4397e-01,  2.0674e+00, -7.7302e-01,  5.9054e-02,  4.7125e-01,\n",
      "           1.1841e+00, -2.4781e-01],\n",
      "         [ 4.9808e-01, -3.9426e-01,  8.7083e-02, -1.0591e+00, -4.5120e-01,\n",
      "           3.0606e-01,  5.6028e-01, -9.3544e-02, -8.1368e-01, -8.5264e-01,\n",
      "           1.5273e+00,  3.4379e-01],\n",
      "         [-6.5232e-01, -1.4073e+00,  1.3769e+00, -1.1888e+00,  1.4919e+00,\n",
      "          -8.6963e-01,  4.0120e-01,  4.9344e-01,  9.9872e-01, -1.3038e+00,\n",
      "           1.1791e+00,  3.8280e-01],\n",
      "         [ 5.1038e-01, -1.6101e+00, -1.1200e+00, -1.3533e-01, -1.1294e+00,\n",
      "           4.6345e-02, -3.6688e-01,  1.2187e+00, -6.9764e-01, -3.4843e-01,\n",
      "           5.9515e-01, -1.7192e+00]],\n",
      "\n",
      "        [[-5.7699e-01,  5.3037e-01,  5.6366e-01, -1.2890e+00,  1.3686e-01,\n",
      "          -1.1180e+00, -2.2650e-01, -3.2879e-01, -7.6662e-01,  9.2224e-01,\n",
      "          -1.4151e+00,  3.2332e-01],\n",
      "         [-7.9569e-01,  6.4677e-01, -1.2872e+00, -5.2245e-01, -9.6771e-01,\n",
      "           1.5296e+00,  6.7592e-01,  5.6934e-01,  6.7648e-01, -4.9463e-01,\n",
      "          -9.0558e-01, -7.4089e-01],\n",
      "         [ 9.2324e-01, -5.9944e-01,  6.3770e-01, -9.9841e-01,  3.0150e-01,\n",
      "          -2.9572e-01,  6.3641e-02,  1.2203e-01, -1.5424e-01, -8.3652e-01,\n",
      "           9.4423e-01, -1.3150e+00],\n",
      "         [ 9.5661e-02,  3.4453e-01, -3.8582e-01, -4.7745e-01, -7.0562e-01,\n",
      "          -4.4474e-01, -7.4595e-01,  3.5416e-01, -4.0191e-01,  1.0691e+00,\n",
      "           1.0817e+00, -2.0387e-02],\n",
      "         [-1.1940e+00, -1.8512e+00,  1.6842e-01,  2.5750e-01,  1.8170e+00,\n",
      "           4.6106e-01,  1.1033e+00, -2.4232e-01,  8.5099e-01, -4.7936e-01,\n",
      "           6.2746e-01, -5.0917e-01],\n",
      "         [ 3.7946e-01,  2.9337e+00,  1.1441e+00, -1.1357e-01,  5.8397e-01,\n",
      "           4.8785e-01, -4.4719e-01,  8.3801e-01, -4.9580e-01,  8.1616e-01,\n",
      "          -3.5345e+00,  1.0282e+00],\n",
      "         [-1.2683e+00,  1.6397e-01,  6.0601e-01, -1.8904e+00,  3.2155e-01,\n",
      "           7.1727e-01,  4.3871e-01, -8.2262e-01,  1.2617e-01, -1.1237e+00,\n",
      "           1.5371e-01, -6.8802e-01],\n",
      "         [ 6.8868e-01,  2.0572e-01,  9.9775e-01, -1.8758e+00,  1.8055e+00,\n",
      "           1.7541e+00,  1.5552e+00, -1.5778e+00, -1.1384e-01, -6.8469e-03,\n",
      "           1.8151e-01, -1.1210e-01],\n",
      "         [ 5.5765e-01, -6.5956e-01, -6.6683e-01,  1.2482e+00,  1.3897e-01,\n",
      "           2.9462e-01,  5.7476e-01,  1.6108e+00,  2.0871e+00, -3.1579e-01,\n",
      "          -1.0462e+00, -3.7980e+00],\n",
      "         [ 1.4411e+00, -2.0263e+00,  6.2314e-02, -1.7618e+00,  1.0215e-01,\n",
      "           9.7898e-02, -1.5422e-01, -9.1021e-01,  3.1409e-01,  5.6573e-01,\n",
      "           2.1619e-01,  8.0124e-01]],\n",
      "\n",
      "        [[ 4.0073e-01,  3.5686e-02, -9.2989e-01, -1.9497e+00, -7.9881e-01,\n",
      "          -1.4790e-01, -4.1716e-01,  1.0576e+00,  1.6814e+00, -6.1594e-01,\n",
      "          -6.3963e-01,  4.0160e-02],\n",
      "         [ 5.5337e-01,  1.1803e-01,  8.9745e-02,  7.2485e-01, -4.4707e-01,\n",
      "          -1.9517e-01,  4.0904e-01,  1.4770e+00,  1.4504e+00, -1.0724e+00,\n",
      "          -9.3107e-01,  9.5385e-01],\n",
      "         [ 1.8203e+00,  8.3799e-01,  1.2699e-02, -3.9442e-01, -3.7014e-01,\n",
      "           1.2714e+00,  1.9055e-01,  1.1347e+00,  3.9957e-01,  1.4378e+00,\n",
      "          -3.8853e-01,  5.5962e-01],\n",
      "         [-1.4258e+00,  5.3996e-01, -1.1027e+00,  8.5735e-01, -7.4439e-01,\n",
      "          -1.0336e+00,  3.8909e-01,  3.7783e-01,  3.0271e-02, -6.0914e-01,\n",
      "           1.9570e+00,  3.7801e-01],\n",
      "         [ 4.4111e-01, -1.1153e+00, -2.2270e+00,  6.3182e-01, -1.0081e+00,\n",
      "           5.3706e-03, -5.9074e-01,  1.0745e+00, -6.2135e-01, -8.0670e-01,\n",
      "          -2.3299e-01, -8.8140e-01],\n",
      "         [-1.8765e-01, -3.7878e-01,  3.5921e-02,  1.2952e+00, -2.5599e-01,\n",
      "          -1.2894e+00,  5.2960e-01,  6.6752e-01,  8.4764e-01,  1.0005e+00,\n",
      "           1.2696e+00,  1.3199e+00],\n",
      "         [-6.7804e-01, -2.1404e-01, -1.1939e+00,  1.7208e-02, -1.1246e+00,\n",
      "           1.1346e+00,  2.5150e-02, -7.9681e-01,  7.4829e-01, -7.3330e-01,\n",
      "          -1.0139e+00,  5.9641e-01],\n",
      "         [-5.3967e-01, -5.9073e-01, -1.3975e+00,  8.3061e-02, -2.8115e-01,\n",
      "           9.0234e-01, -5.9801e-01,  3.9357e-01,  3.4611e-02, -1.1745e+00,\n",
      "           1.5550e-01, -4.0732e-01],\n",
      "         [-1.0970e+00,  2.4461e-01,  5.9455e-01,  4.8718e-01,  4.2092e-01,\n",
      "           2.7991e-01,  2.0462e+00,  5.8090e-01, -2.5685e-01,  7.5300e-01,\n",
      "          -1.5956e+00,  8.2626e-01],\n",
      "         [ 5.6943e-01,  6.8492e-01,  2.3104e-01,  2.4234e-01, -2.1947e-01,\n",
      "          -2.5481e-01, -3.1391e-01,  1.5910e+00,  4.4878e-01,  9.3107e-01,\n",
      "           2.8964e-01,  1.1696e+00]],\n",
      "\n",
      "        [[-5.0064e-02, -2.7785e-01,  1.5376e+00, -2.3408e+00, -1.1305e+00,\n",
      "          -5.6128e-01,  1.4601e+00, -1.1516e+00,  6.4470e-01, -4.3133e-01,\n",
      "          -8.5644e-01,  2.9693e-01],\n",
      "         [ 4.9341e-01, -8.2876e-01, -7.8549e-01, -3.2644e-01, -3.7612e-01,\n",
      "           8.6960e-01,  9.6066e-01,  8.2722e-01, -4.1275e-01,  1.2027e+00,\n",
      "           2.6234e-01,  4.6464e-01],\n",
      "         [ 7.5358e-02,  2.7383e-01, -4.4980e-01,  1.0120e+00,  1.3928e+00,\n",
      "           1.0477e+00, -4.4730e-01,  1.0002e+00,  3.3261e-01, -3.3373e-01,\n",
      "          -2.4043e-01, -8.8929e-01],\n",
      "         [ 1.7777e+00,  4.3522e-02, -1.5864e+00, -8.5111e-01,  2.3328e-01,\n",
      "          -4.2255e-01, -7.4724e-01,  6.9250e-01, -3.1969e-01, -7.4060e-01,\n",
      "           7.7544e-01,  7.7630e-01],\n",
      "         [-7.5195e-01, -5.0775e-01, -8.1711e-01, -7.5156e-01, -2.2068e+00,\n",
      "          -5.0686e-01, -1.0017e+00, -6.8597e-01,  1.6323e+00,  5.6808e-01,\n",
      "           2.4135e-01, -6.1556e-01],\n",
      "         [-8.9628e-01, -2.4930e+00, -1.2957e+00, -9.7442e-01,  2.6232e-01,\n",
      "           4.5353e-01, -1.0165e+00, -2.0678e-02,  1.0526e+00, -9.4801e-02,\n",
      "          -1.5176e-01, -6.9572e-01],\n",
      "         [ 1.1039e+00, -4.3510e-01,  9.9992e-01, -2.8563e-01, -1.9212e-01,\n",
      "          -1.8717e+00,  4.8985e-01,  4.1628e-01, -7.6246e-01, -6.2498e-01,\n",
      "          -2.2584e+00, -7.9216e-02],\n",
      "         [-7.1036e-01,  8.8019e-01,  1.1094e+00,  1.5276e-01, -6.6120e-02,\n",
      "          -7.7801e-01, -1.3737e+00,  1.4501e+00,  2.4999e+00, -1.6401e-01,\n",
      "          -3.0081e-01,  1.8611e+00],\n",
      "         [-1.3037e+00,  1.5582e-01,  3.5396e-01, -1.1153e+00, -1.0327e+00,\n",
      "          -6.1311e-01, -7.2637e-01,  5.6331e-01, -5.5400e-01, -7.1746e-01,\n",
      "          -8.1416e-01,  6.5634e-01],\n",
      "         [ 8.7187e-01, -1.2159e-01, -1.4963e+00,  8.6013e-01,  1.0124e+00,\n",
      "           7.0790e-01,  1.3517e-01,  1.0228e-01, -2.3684e-01,  4.2258e-01,\n",
      "           5.7445e-01,  2.2393e-01]],\n",
      "\n",
      "        [[ 3.8169e-01,  1.3692e+00, -1.2741e+00, -1.6359e-02, -1.6884e-02,\n",
      "          -6.3857e-01, -1.3939e-04, -7.2066e-02,  2.1871e+00, -1.4545e+00,\n",
      "          -1.0793e+00, -1.4602e+00],\n",
      "         [ 4.4817e-01, -3.8012e-01, -4.7769e-01, -2.1934e-01,  3.9296e-02,\n",
      "           2.7272e-01,  1.0709e+00,  4.2406e-01,  1.7754e+00,  2.9393e-01,\n",
      "           8.1894e-01, -2.1838e-01],\n",
      "         [-6.0734e-01,  4.0870e-01, -7.1180e-01, -1.9928e-01,  9.4987e-01,\n",
      "          -1.4908e+00,  3.6325e-01,  1.9567e+00,  3.4381e-01, -1.3566e+00,\n",
      "           1.4024e-01,  2.8970e-01],\n",
      "         [-3.0569e-01, -7.2370e-02,  4.7900e-02, -1.5788e-01, -1.1427e+00,\n",
      "           3.1729e-01, -1.2438e+00,  3.5309e-01, -1.1121e+00,  6.1281e-01,\n",
      "          -8.8599e-01, -1.0167e+00],\n",
      "         [ 1.6146e+00,  1.0365e+00,  4.3324e-01, -4.4319e-01, -7.1850e-01,\n",
      "           5.3738e-02, -1.6225e+00,  8.2688e-01,  6.8180e-01,  5.0989e-01,\n",
      "          -1.5191e+00,  8.5459e-01],\n",
      "         [-1.2392e+00,  2.4948e-01, -5.9547e-04, -2.8866e-01, -1.4928e+00,\n",
      "           4.7904e-02, -1.3827e+00, -1.2726e+00, -1.1426e-01, -2.0372e+00,\n",
      "           3.3651e-01, -5.5327e-01],\n",
      "         [ 7.5260e-01, -1.8928e-02,  7.7255e-01, -1.1964e+00, -8.9953e-01,\n",
      "          -1.0385e+00,  1.2675e-02,  1.6788e+00, -2.6896e-01, -4.7489e-01,\n",
      "           4.7909e-01, -1.0642e+00],\n",
      "         [-6.9838e-01,  1.6440e+00,  4.3177e-02, -1.5434e+00, -1.6646e+00,\n",
      "          -1.0100e+00,  6.5384e-01, -2.9346e-01,  6.3440e-01, -6.2117e-01,\n",
      "          -2.1322e+00, -1.8889e+00],\n",
      "         [-1.4016e+00, -1.7030e-01,  9.4399e-01,  1.9983e+00,  1.4981e+00,\n",
      "          -1.7627e+00,  3.2355e-01, -1.1244e+00,  1.2908e+00,  1.2037e-01,\n",
      "           9.0410e-01, -1.4195e-01],\n",
      "         [-2.1435e-01, -1.1997e+00, -5.8909e-01, -7.4136e-01,  4.3459e-01,\n",
      "          -6.2763e-01,  7.3892e-01,  2.0339e-01,  1.4749e+00,  3.6197e-01,\n",
      "          -1.3570e+00,  1.0111e+00]],\n",
      "\n",
      "        [[ 5.5139e-01, -1.3757e+00, -5.7431e-01,  9.1646e-01,  1.3973e+00,\n",
      "          -1.7425e+00, -8.7810e-01, -2.6248e-01, -1.0358e+00, -1.1836e+00,\n",
      "          -1.8635e+00,  3.2662e+00],\n",
      "         [-9.4651e-02,  5.3699e-01,  1.5976e+00, -1.0184e+00,  1.5613e+00,\n",
      "          -8.2626e-01, -1.2167e+00,  3.6695e-01, -5.7384e-01, -2.3971e-01,\n",
      "           1.1029e+00,  5.8090e-01],\n",
      "         [ 9.5054e-01,  1.9140e+00,  9.2239e-01,  8.0488e-01, -9.9589e-01,\n",
      "           3.5472e-01, -1.6014e+00, -1.1396e+00,  2.8069e-03, -9.9893e-01,\n",
      "           2.5034e-01,  1.0745e+00],\n",
      "         [ 2.5637e-01, -6.8960e-01, -2.3172e+00,  5.6974e-01, -6.5364e-01,\n",
      "          -3.1056e-01,  1.9474e-01,  1.6677e+00, -2.2103e-02, -8.8091e-01,\n",
      "          -6.8464e-01, -1.4915e+00],\n",
      "         [ 1.7497e+00,  7.1501e-01, -2.2142e-01, -3.8188e-01, -3.0454e-01,\n",
      "          -1.0518e+00, -3.5503e-01,  1.0833e+00,  3.2740e-01,  5.3380e-01,\n",
      "          -8.3922e-01, -4.7011e-02],\n",
      "         [ 1.0637e-02,  1.6167e+00,  1.1551e+00,  4.3533e-02, -1.8285e+00,\n",
      "           1.2683e+00, -7.6926e-02,  2.4612e+00,  1.0765e-01, -1.1239e+00,\n",
      "          -2.4323e-01,  3.3172e-01],\n",
      "         [ 2.9031e-01, -1.2218e+00,  4.8270e-01,  6.5482e-02, -5.5709e-01,\n",
      "          -5.5391e-01,  2.5262e-01, -2.2084e+00, -4.2132e-01, -7.7817e-02,\n",
      "           1.6287e-02,  8.3517e-01],\n",
      "         [ 4.1827e-01,  6.4901e-01,  8.0253e-01, -2.1073e-01,  2.1637e+00,\n",
      "          -7.9145e-02, -8.6939e-01,  8.8225e-01,  3.1269e-01, -7.4005e-01,\n",
      "          -7.2871e-01, -4.1319e-01],\n",
      "         [-8.3380e-01,  2.1294e+00,  1.6689e+00,  1.5195e+00,  8.1986e-01,\n",
      "          -4.9573e-01, -8.1142e-01, -1.2811e+00,  5.1268e-01, -1.5650e+00,\n",
      "          -6.2515e-01,  1.3383e+00],\n",
      "         [ 3.0740e-01,  2.9553e-01,  1.2654e+00,  1.3198e+00,  5.0892e-01,\n",
      "          -5.6298e-01, -2.0615e-01, -2.2720e-01,  4.7010e-01, -1.3603e+00,\n",
      "          -7.2905e-02,  1.1284e+00]]])\n",
      "torch.Size([6, 10, 12])\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(6, 10, 12)\n",
    "print(X)\n",
    "print(X.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 10, 12])\n",
      "torch.Size([2, 6, 10, 2])\n",
      "tensor([[[ 2.0342e-01,  3.4062e-01, -5.3461e-02,  1.7939e-01,  4.1577e-01,\n",
      "          -2.6760e-01],\n",
      "         [ 2.0257e-01,  3.4769e-01, -8.5435e-02,  1.4806e-01,  4.9734e-01,\n",
      "          -2.8467e-01],\n",
      "         [ 2.1995e-01,  2.4925e-01, -3.6779e-03,  1.6946e-01,  4.5658e-01,\n",
      "          -2.3527e-01],\n",
      "         [ 2.1141e-01,  2.9893e-01, -3.1834e-02,  1.8276e-01,  4.1040e-01,\n",
      "          -2.4414e-01],\n",
      "         [ 1.8845e-01,  4.0583e-01, -4.1880e-02,  1.6045e-01,  4.6153e-01,\n",
      "          -2.9468e-01],\n",
      "         [ 1.4068e-01,  4.4603e-01, -2.6512e-01,  1.1452e-01,  3.2217e-01,\n",
      "          -1.3647e-01],\n",
      "         [ 1.3684e-01,  4.0859e-01, -2.2066e-01,  1.2875e-01,  3.9079e-01,\n",
      "          -2.0597e-01],\n",
      "         [ 1.2489e-01,  4.0010e-01, -2.1458e-01,  1.2532e-01,  3.7144e-01,\n",
      "          -1.8546e-01],\n",
      "         [ 1.2418e-01,  3.6196e-01, -1.7459e-01,  1.2473e-01,  3.6365e-01,\n",
      "          -1.7481e-01],\n",
      "         [ 9.3679e-02,  3.5114e-01, -1.7168e-01,  1.3597e-01,  4.0312e-01,\n",
      "          -2.1436e-01]],\n",
      "\n",
      "        [[ 1.2385e-01,  1.3882e-01, -1.5392e-01,  1.8054e-01,  1.4507e-01,\n",
      "          -1.4702e-01],\n",
      "         [ 1.5899e-01,  1.4453e-01, -1.5275e-01,  2.8626e-01,  1.3451e-01,\n",
      "          -1.1955e-01],\n",
      "         [ 1.4886e-01,  1.1754e-01, -1.3217e-01,  2.5925e-01,  1.4457e-01,\n",
      "          -1.2196e-01],\n",
      "         [ 2.0504e-01,  1.4373e-01, -1.3815e-01,  2.6220e-01,  1.5548e-01,\n",
      "          -1.2383e-01],\n",
      "         [ 3.2638e-01,  1.4337e-01, -1.0804e-01,  2.6460e-01,  1.4347e-01,\n",
      "          -1.2048e-01],\n",
      "         [-2.2547e-01, -1.4351e-01, -3.2770e-01, -2.9791e-01, -7.6919e-02,\n",
      "          -3.1892e-01],\n",
      "         [-1.2125e-01, -9.0357e-02, -3.1594e-01,  4.2567e-01,  4.0092e-03,\n",
      "          -3.1809e-01],\n",
      "         [ 7.6202e-01, -3.3093e-02, -3.4220e-01,  2.5814e-01,  4.9289e-02,\n",
      "          -2.9537e-01],\n",
      "         [-1.1399e-01, -1.5908e-01, -3.3643e-01,  2.0995e-01, -4.4424e-02,\n",
      "          -3.2063e-01],\n",
      "         [ 6.5509e-01, -4.2459e-03, -3.3045e-01,  5.6590e-01,  2.0959e-02,\n",
      "          -3.1942e-01]],\n",
      "\n",
      "        [[ 9.7335e-02,  1.2838e-01, -1.0780e-01,  7.0572e-01,  3.3694e-01,\n",
      "           7.1612e-02],\n",
      "         [ 3.7296e-01,  2.4515e-01, -6.2896e-02,  2.1467e-01,  1.8069e-01,\n",
      "          -9.5782e-02],\n",
      "         [ 5.8384e-01,  3.2918e-01, -9.1975e-04,  2.1965e-01,  1.9834e-01,\n",
      "          -1.0035e-01],\n",
      "         [ 2.4224e-01,  1.9421e-01, -9.1904e-02,  2.0823e-01,  1.8092e-01,\n",
      "          -9.7615e-02],\n",
      "         [ 2.8964e-01,  2.0510e-01, -7.6562e-02,  5.5259e-01,  2.9818e-01,\n",
      "           1.4392e-03],\n",
      "         [ 4.3562e-01,  3.7217e-01,  4.7793e-02,  2.8105e-01,  1.9319e-01,\n",
      "          -2.5438e-01],\n",
      "         [ 3.0648e-01,  4.1092e-01,  1.4810e-02,  3.7424e-01,  4.4011e-01,\n",
      "           5.8503e-02],\n",
      "         [ 2.6056e-01,  3.5601e-01, -4.9874e-02,  3.7470e-01,  4.2755e-01,\n",
      "           5.1739e-02],\n",
      "         [ 3.8880e-01,  3.9544e-01,  3.6907e-02,  2.5806e-01,  1.6496e-01,\n",
      "          -2.9541e-01],\n",
      "         [ 3.6686e-01,  3.2021e-01, -5.2688e-02,  2.9478e-01,  2.1920e-01,\n",
      "          -2.1496e-01]],\n",
      "\n",
      "        [[ 2.1615e-01,  2.5326e-01, -3.9306e-01,  1.1772e-01,  1.7532e-01,\n",
      "          -2.4395e-01],\n",
      "         [ 2.0969e-01,  2.3539e-01, -3.7886e-01,  5.9847e-02,  1.3117e-01,\n",
      "          -1.6459e-01],\n",
      "         [ 1.1165e-01,  1.6953e-01, -2.4052e-01,  1.3078e-01,  1.8688e-01,\n",
      "          -2.6722e-01],\n",
      "         [ 8.6777e-02,  1.4220e-01, -2.0132e-01,  1.7224e-01,  2.1933e-01,\n",
      "          -3.2651e-01],\n",
      "         [ 1.0552e-01,  1.6314e-01, -2.3259e-01,  3.3608e-01,  3.0976e-01,\n",
      "          -5.4327e-01],\n",
      "         [ 2.4955e-01,  7.1155e-02,  1.9891e-01,  5.1094e-01, -6.5838e-02,\n",
      "          -1.2305e-01],\n",
      "         [ 4.7880e-01,  1.7896e-01, -1.7492e-01,  2.1782e-01,  8.0491e-02,\n",
      "           5.1311e-02],\n",
      "         [ 1.8730e-01,  2.9631e-02,  3.3679e-01,  2.7303e-01,  9.3486e-02,\n",
      "           1.0575e-01],\n",
      "         [ 2.1583e-01,  7.8928e-02,  2.9077e-02,  3.0391e-01,  9.0562e-02,\n",
      "           1.0926e-01],\n",
      "         [ 3.9982e-01,  5.5168e-02,  4.0586e-02,  3.2237e-01,  8.7609e-02,\n",
      "           1.0176e-01]],\n",
      "\n",
      "        [[ 2.7583e-01,  3.2289e-02, -2.9615e-02,  3.8186e-01, -1.6723e-02,\n",
      "           5.6993e-02],\n",
      "         [ 2.9560e-01, -9.5815e-02,  2.5571e-04,  2.7984e-01, -7.3903e-02,\n",
      "          -8.0362e-03],\n",
      "         [ 2.1788e-01, -2.3789e-02, -4.3934e-02,  2.6791e-01, -2.3723e-04,\n",
      "          -2.4868e-02],\n",
      "         [ 3.1873e-01,  1.1049e-02,  2.9166e-03,  2.8761e-01, -6.7750e-02,\n",
      "          -4.2460e-03],\n",
      "         [ 2.9246e-01, -1.9459e-02, -6.7087e-03,  2.9709e-01, -4.0992e-02,\n",
      "          -8.8413e-04],\n",
      "         [ 2.8816e-01, -3.5129e-02, -2.7377e-02,  7.2118e-01, -2.2952e-01,\n",
      "          -6.5452e-02],\n",
      "         [ 2.4364e-01, -4.6695e-03, -4.0398e-02,  1.6534e-01,  4.7775e-02,\n",
      "          -5.1464e-02],\n",
      "         [ 1.4545e-01,  6.9632e-03, -8.3303e-02,  4.8507e-01, -1.1108e-01,\n",
      "          -3.3771e-03],\n",
      "         [ 5.4822e-01, -1.4940e-01, -1.5509e-02,  2.0328e-01,  1.5711e-02,\n",
      "          -5.2743e-02],\n",
      "         [ 3.0757e-01, -3.1057e-02, -1.0066e-02,  4.4659e-01, -9.8009e-02,\n",
      "          -5.9074e-03]],\n",
      "\n",
      "        [[ 3.9047e-01, -1.3821e-01,  4.4270e-01,  4.3845e-01, -1.3151e-01,\n",
      "           4.4885e-01],\n",
      "         [ 2.9516e-01, -1.4899e-01,  3.6406e-01,  2.7104e-01, -1.4614e-01,\n",
      "           3.7227e-01],\n",
      "         [ 4.9142e-01, -4.7818e-02,  5.6069e-01,  3.7360e-01, -1.4336e-01,\n",
      "           4.3626e-01],\n",
      "         [ 3.7002e-01, -1.6104e-01,  3.7746e-01,  3.9822e-01, -1.4032e-01,\n",
      "           4.6400e-01],\n",
      "         [ 3.6429e-01, -1.4409e-01,  4.1261e-01,  3.2085e-01, -1.4832e-01,\n",
      "           3.8347e-01],\n",
      "         [ 5.2656e-01, -1.8130e-01,  3.3158e-01,  2.7008e-01, -1.1850e-01,\n",
      "           8.8531e-02],\n",
      "         [ 7.5575e-01, -1.8712e-01,  5.6573e-01,  5.2243e-01, -1.8322e-01,\n",
      "           3.8536e-01],\n",
      "         [ 4.8488e-01, -1.7865e-01,  2.8739e-01,  5.7058e-01, -1.8409e-01,\n",
      "           3.8071e-01],\n",
      "         [ 6.7322e-01, -1.8473e-01,  4.3169e-01,  5.6213e-01, -1.9392e-01,\n",
      "           3.3930e-01],\n",
      "         [ 6.7126e-01, -1.8859e-01,  4.7967e-01,  4.7820e-01, -1.7839e-01,\n",
      "           2.8008e-01]]], grad_fn=<ReshapeAliasBackward0>)\n",
      "torch.Size([6, 10, 6])\n"
     ]
    }
   ],
   "source": [
    "self_attention = SelfAttentionMultiHead(12, 4, 6, 2)\n",
    "res = self_attention(X)\n",
    "print(res)\n",
    "print(res.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('research')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b361d90544c21c7e570702d0c4d23653c8dcac4c1ecf309667aae54eeacb0d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
